# GitHub Events Data Warehouse ğŸš€

> Production-ready ETL pipeline processing GitHub's public events API into a dimensional data warehouse using **Medallion Architecture** (Bronze â†’ Silver â†’ Gold)

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue.svg)](https://www.postgresql.org/)
[![Architecture](https://img.shields.io/badge/Architecture-Medallion-green.svg)](https://www.databricks.com/glossary/medallion-architecture)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)

---

## ğŸ“Š Project Overview


A robust, near real-time data pipeline that ingests high-volume public GitHub events into a PostgreSQL Data Warehouse using a **Medallion Architecture** (Bronze $\rightarrow$ Silver $\rightarrow$ Gold).

Currently, the **Ingestion Layer**, **Bronze Layer**, **Silver Layer**, and **Gold Layer** are fully operational.

## ğŸ— Architecture

The pipeline uses a **Stateless Sliding Window** for ingestion and an **Incremental Batch** strategy for transformation.

### **Medallion Pattern (Bronze â†’ Silver â†’ Gold)**

```mermaid
graph TD
    %% Nodes
    GitHub[GitHub API <br/> /events]
    
    subgraph Ingestion_Layer [Python Ingestion Layer]
        Orch[Orchestrator <br/> main.py]
        Fetcher[API Client]
        Loader[Bronze Loader]
    end
    
    subgraph Storage_Layer [PostgreSQL Warehouse]
        Bronze[(Bronze Layer <br/> raw_events)]
        DLQ[(Dead Letter Queue <br/> bad_data)]
        Silver[(Silver Layer <br/> events)]
        Gold[(Gold Layer <br/> Star Schema)]
    end

    subgraph ETL_Layer [Python ETL Scheduler]
        Scheduler[process_etl.py]
        SilverProc[Silver Processor]
        GoldProc[Gold Processor]
    end

    %% Flow
    Orch -->|Trigger 60s| Fetcher
    GitHub -.->|JSON Stream| Fetcher
    Fetcher -.->|List of Events| Loader
    
    Loader -->|Raw JSONB| Bronze
    Loader -.->|Failed Rows| DLQ
    
    Scheduler -->|Trigger| SilverProc
    SilverProc -->|Read New| Bronze
    SilverProc -->|Cleaned Data| Silver
    
    Scheduler -->|Trigger| GoldProc
    GoldProc -->|Read| Silver
    GoldProc -->|Update Dims & Facts| Gold

    %% Styling
    classDef storage fill:#e1f5fe,stroke:#01579b,stroke-width:2px;
    classDef process fill:#fff3e0,stroke:#ff6f00,stroke-width:2px;
    class Bronze,DLQ,Silver,Gold storage;
    class Fetcher,Loader,SilverProc,GoldProc,Orch,Scheduler process;
```

### **Data Flow**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BRONZE LAYER (Raw Storage)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Continuous ingestion (every 60 seconds)                   â”‚
â”‚ â€¢ Raw JSONB storage (immutable audit trail)                 â”‚
â”‚ â€¢ Deduplication (ON CONFLICT DO NOTHING)                    â”‚
â”‚ â€¢ Dead Letter Queue (failed rows isolation)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SILVER LAYER (Transformation)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Incremental batch processing (anti-join pattern)          â”‚
â”‚ â€¢ Type casting with sentinel values (-1, 'unknownuser')     â”‚
â”‚ â€¢ Data validation & quality checks                          â”‚
â”‚ â€¢ Watermark tracking (processed_at timestamp)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GOLD LAYER (Star Schema)                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Kimball dimensional model (4 dimensions + 1 fact)         â”‚
â”‚ â€¢ Transactional loading (BEGIN...COMMIT)                    â”‚
â”‚ â€¢ Late-arriving data protection (event_time ordering)       â”‚
â”‚ â€¢ Type 1 SCD (slowly changing dimensions)                   â”‚
â”‚ â€¢ Auto-discovery pattern (unknown event types)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â­ Key Features

### **1. Medallion Architecture**
- âœ… **Bronze:** Immutable raw data lake (JSONB storage)
- âœ… **Silver:** Cleaned, validated, structured data
- âœ… **Gold:** Business-ready star schema for analytics

### **2. Industrial-Grade ETL Patterns**
- âœ… **Watermark-based incremental loading** (processes only new data)
- âœ… **Transactional ETL** (all-or-nothing, automatic rollback on failure)
- âœ… **Idempotent operations** (safe to re-run, no duplicates)
- âœ… **Late-arriving data handling** (ORDER BY event_time prevents overwrites)

### **3. Data Quality & Reliability**
- âœ… **Dead Letter Queue** (failed rows don't crash pipeline)
- âœ… **Sentinel values** (-1 for invalid IDs, 'unknownuser' for missing data)
- âœ… **Safe type casting** (regex validation before BIGINT conversion)
- âœ… **FK constraint enforcement** (fail-fast vs silent data loss)

### **4. Operational Excellence**
- âœ… **Dual logging** (console + file-based logs per layer)
- âœ… **Graceful shutdown** (Ctrl+C finishes current batch)
- âœ… **Demo vs Production modes** (2-min cycles vs daily 2 AM runs)
- âœ… **Performance timing** (per-step duration tracking)

### **5. Schema Design**
- âœ… **Star schema** (Kimball methodology)
- âœ… **Smart date keys** (YYYYMMDD INT format for performance)
- âœ… **Type 1 SCD** (dimensions track current state)
- âœ… **Immutable facts** (historical events never change)

---

## ğŸ“ Gold Layer Schema

### **Star Schema Design**

```mermaid
erDiagram
    DIM_DATE {
        INT date_id PK
        DATE full_date
        INT year
        INT quarter
        BOOLEAN is_weekend
        INT month
    }

    DIM_ACTORS {
        BIGINT actor_id PK
        TEXT actor_login
        TIMESTAMP updated_at
        TIMESTAMP last_event_time
    }

    DIM_REPOS {
        BIGINT repo_id PK
        TEXT repo_name
        TEXT repo_owner
        TEXT org_login
        TIMESTAMP updated_at
    }

    DIM_EVENT_TYPES {
        TEXT event_type PK
        TEXT category
        BOOLEAN is_core_metric
    }

    FACT_EVENTS {
        BIGINT event_id PK
        INT date_id FK
        BIGINT actor_id FK
        BIGINT repo_id FK
        TEXT event_type FK
        TIMESTAMP event_time
        INT event_hour
        TIMESTAMP silver_processed_at
    }

    DIM_DATE ||--o{ FACT_EVENTS : date_id
    DIM_ACTORS ||--o{ FACT_EVENTS : actor_id
    DIM_REPOS ||--o{ FACT_EVENTS : repo_id
    DIM_EVENT_TYPES ||--o{ FACT_EVENTS : event_type
```

### **Dimensions**
1. **dim_date**  - Calendar dimension 2020-2030
2. **dim_actors**  - GitHub users
3. **dim_repos**  - Repositories
4. **dim_event_types**  - Event taxonomy with auto-discovery

### **Fact Table**
- **fact_events**  - GitHub events with FK references

---

## ğŸ› ï¸ Tech Stack

| Category | Technology |
|----------|-----------|
| **Language** | Python 3.10+ |
| **Database** | PostgreSQL 16 |
| **Data Model** | Kimball Star Schema |
| **Architecture** | Medallion (Bronze/Silver/Gold) |
| **Libraries** | psycopg2, requests, python-dotenv |
| **Patterns** | Watermark-based incremental ETL, Type 1 SCD |

---

## ğŸš€ Quick Start

### **1. Prerequisites**

- Python 3.10+
- PostgreSQL 16
- GitHub account (optional, for higher API limits)

### **2. Installation**

```bash
# Clone repository
git clone https://github.com/yourusername/github-pipeline.git
cd github-pipeline

# Install dependencies
pip install -r requirements.txt
```

### **3. Configuration**

Create `.env` file in project root:

```ini
DB_HOST=localhost
DB_NAME=github_events
DB_USER=postgres
DB_PASS=your_secure_password
DB_PORT=5432
GITHUB_TOKEN=ghp_your_token_here  # Optional (5000 req/hr vs 60)
```

### **4. Database Initialization**

```bash
# Create schemas (Bronze, Silver, Gold)
python setup_db.py

# Create Gold star schema
psql -U postgres -d github_events -f warehouse/gold/01_dim_date.sql
psql -U postgres -d github_events -f warehouse/gold/02_dim_actors.sql
psql -U postgres -d github_events -f warehouse/gold/03_dim_repos.sql
psql -U postgres -d github_events -f warehouse/gold/04_dim_event_types.sql
psql -U postgres -d github_events -f warehouse/gold/05_fact_events.sql

# Create Silver view
psql -U postgres -d github_events -f warehouse/silver/view_silver.sql
```

### **5. Run Pipeline**

**Two separate processes:**

**Terminal 1: Bronze Ingestion (Continuous)**
```bash
python ingestion/src/main.py

# Output:
# ğŸ”µ BRONZE LAYER - CONTINUOUS INGESTION
# Schedule: Every 60 seconds
# âœ… Ingested 95 events in 1.23s
# ğŸ’¤ Next poll in 58 seconds...
```

**Terminal 2: Silver + Gold ETL (Scheduled)**
```bash
python ingestion/src/process_etl.py

# Output:
# âšªğŸŸ¡ SILVER + GOLD ETL SCHEDULER
# Mode: DEMO (2-min cycles)
# [1/2] Silver Layer: Transforming Bronze â†’ Silver...
# âœ… Silver: Completed in 2.34s
# [2/2] Gold Layer: Loading Star Schema...
# âœ… Gold: Completed in 1.56s
```

---

## âš™ï¸ Configuration Modes

### **Demo Mode (Default)** - For Testing/Portfolio
```python
# ingestion/src/process_etl.py
DEMO_MODE = True  # Runs every 2 minutes
```

### **Production Mode** - For Real Deployment
```python
# ingestion/src/process_etl.py
DEMO_MODE = False  # Runs daily at 2:00 AM
```

---

## ğŸ“Š Sample Analytics Queries

### **Q1: Daily Event Volume (Last 7 Days)**
```sql
SELECT 
    d.full_date,
    COUNT(*) as total_events,
    COUNT(DISTINCT f.actor_id) as unique_users,
    COUNT(DISTINCT f.repo_id) as unique_repos
FROM gold.fact_events f
JOIN gold.dim_date d ON f.date_id = d.date_id
WHERE d.full_date >= CURRENT_DATE - 7
GROUP BY d.full_date
ORDER BY d.full_date;
```

### **Q2: Top 10 Most Active Repositories (This Month)**
```sql
SELECT 
    r.repo_name,
    r.repo_owner,
    COUNT(*) as total_events,
    COUNT(DISTINCT f.actor_id) as contributors
FROM gold.fact_events f
JOIN gold.dim_repos r ON f.repo_id = r.repo_id
JOIN gold.dim_date d ON f.date_id = d.date_id
WHERE d.year = EXTRACT(YEAR FROM CURRENT_DATE)
  AND d.month = EXTRACT(MONTH FROM CURRENT_DATE)
GROUP BY r.repo_name, r.repo_owner
ORDER BY total_events DESC
LIMIT 10;
```

### **Q3: Hourly Activity Pattern (Weekday vs Weekend)**
```sql
SELECT 
    f.event_hour,
    d.is_weekend,
    COUNT(*) as events
FROM gold.fact_events f
JOIN gold.dim_date d ON f.date_id = d.date_id
WHERE d.full_date >= CURRENT_DATE - 30
GROUP BY f.event_hour, d.is_weekend
ORDER BY d.is_weekend, f.event_hour;
```

---

## ğŸ“ Project Structure

```
github-pipeline/
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ process_etl.py
â”‚   â”‚   â”œâ”€â”€ process_silver.py
â”‚   â”‚   â”œâ”€â”€ process_gold.py
â”‚   â”‚   â”œâ”€â”€ api_client.py
â”‚   â”‚   â”œâ”€â”€ bronze_loader.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â””â”€â”€ logs/
â”‚
â”œâ”€â”€ warehouse/
â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â””â”€â”€ ddl.sql
â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â”œâ”€â”€ ddl.sql
â”‚   â”‚   â””â”€â”€ view_silver.sql
â”‚   â””â”€â”€ gold/
â”‚       â”œâ”€â”€ 01_dim_date.sql
â”‚       â”œâ”€â”€ 02_dim_actors.sql
â”‚       â”œâ”€â”€ 03_dim_repos.sql
â”‚       â”œâ”€â”€ 04_dim_event_types.sql
â”‚       â”œâ”€â”€ 05_fact_events.sql
â”‚       â””â”€â”€ etl/
â”‚           â””â”€â”€ master_gold_etl.sql
â”‚
â”œâ”€â”€ data_samples/
â”‚   â””â”€â”€ github_events_sample.json
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup_db.py
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸ¯ Design Decisions & Learnings

### **1. Why Two Separate Processes?**
- **Bronze (continuous):** Captures events in real-time, minimizes data loss
- **Silver + Gold (scheduled):** Batch processing is more efficient than row-by-row

### **2. Why Watermark Instead of Full Scans?**
- Processes only new data (99% faster for incremental loads)
- Scales to billions of rows
- Industry standard (Snowflake, Databricks, BigQuery)

### **3. Why ORDER BY event_time Instead of processed_at?**
- Prevents late-arriving old data from overwriting current data
- Example: Event from yesterday arrives today â†’ Should not overwrite current dimension values

### **4. Why Transactional ETL (BEGIN...COMMIT)?**
- All-or-nothing: If Gold fails, dimensions roll back automatically
- No partial failures, no silent data loss
- Watermark unchanged on failure â†’ Auto-retry next run

### **5. Why Sentinel Values Instead of NULLs?**
- FK constraints require valid references
- -1 actor_id â†’ "unknownuser" dimension row
- Enables pipeline to continue vs crashing on bad data

---

## ğŸ“ˆ Performance Metrics

| Metric | Value |
|--------|-------|
| **Bronze ingestion** | ~100 events/minute |
| **Silver batch size** | 5,000 rows |
| **Gold ETL duration** | ~3 seconds (1,000 events) |
| **Storage** | ~500 MB per 1M events (JSONB) |
| **Indexes** | 7 (Silver), 9 (Gold) for query performance |

---

## ğŸ” Monitoring & Observability

### **Log Files**
```
ingestion/logs/
â”œâ”€â”€ pipeline.log
â”œâ”€â”€ bronze.log
â”œâ”€â”€ silver.log
â””â”€â”€ silver_gold_etl.log
```

### **Health Checks**
```sql
SELECT MAX(silver_processed_at) FROM gold.fact_events;

SELECT COUNT(*) FROM bronze.raw_events b
WHERE NOT EXISTS (SELECT 1 FROM silver.events s WHERE s.event_id = b.event_id);

SELECT COUNT(*) FROM gold.fact_events WHERE actor_id = -1;
SELECT COUNT(*) FROM gold.fact_events WHERE repo_id = -1;
```

---

## ğŸš§ Roadmap

### **Completed âœ…**
- [x] Bronze layer (raw JSONB storage + DLQ)
- [x] Silver layer (incremental transformations)
- [x] Gold layer (star schema with 4 dimensions)
- [x] Watermark-based incremental loading
- [x] Transactional ETL (all-or-nothing)
- [x] Late-arriving data protection
- [x] Demo vs Production modes

### **Next Steps ğŸ¯**
- [ ] Apache Airflow orchestration (DAGs for scheduling)
- [ ] AWS deployment (EC2 + RDS)
- [ ] Data quality tests (Great Expectations)
- [ ] Dashboard/BI integration (Metabase/Tableau)
- [ ] CI/CD pipeline (GitHub Actions)

---

## ğŸ“š Learning Resources

This project implements patterns from:
- **Kimball's Data Warehouse Toolkit** (dimensional modeling)
- **Databricks Medallion Architecture** (Bronze/Silver/Gold)
- **Snowflake Best Practices** (watermark-based loading)
- **Enterprise ETL Patterns** (transactional, idempotent operations)

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details

---

## ğŸ‘¤ Author

**Ragesh**

---

**â­ If you found this project helpful, please consider giving it a star!**
